model_name: meta-llama/Llama-2-7b-hf
show_name: llama2-7b
batch_size: 8
torch_dtype: bf16
template: "{input} {prompt}"
system_message: null
ppl_template: "{input} {prompt}"

generation_configs:
  do_sample: false
  max_new_tokens: 60
  num_return_sequences: 1
  top_p: null
  top_k: null
